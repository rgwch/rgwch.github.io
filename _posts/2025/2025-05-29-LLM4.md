---
layout: post
title: Intelligente Texterkennung
date: 2025-05-29
tags: [KI,LLM]
category: 
---

Nachdem ich im [letzten Teil](/2025/05/LLM3) gezeigt habe, wie das LLM einen langen Bericht, typischerweise in PDF-Form, zusammenfassen kann, sei hier noch kurz auf eine andere Möglichkeit eingegangen: Die KI kann das Problem des "PDF-Friedhofs" elektronische KG zu lösen helfen, indem es PDFs auch semantisch analysieren kann.

`ollama run gemma3:12b`

<span style="color:green">&gt;Bitte finde die Diagnosen in diesem Text: (PDF-Datei)</span>

> Basierend auf dem Text sind die Diagnosen (oder zumindest die Hauptprobleme) wie folgt:
*   **Chronischer Knieschmerz rechts:** Dies ist das Hauptanliegen des Patienten.
*   **DD Überlagerung durch lumbosakrale Schmerzsyndrom:** Eine Differentialdiagnose, die andeutet, dass Rückenschmerzen und ein lumbosakrales Schmerzsyndrom 
die Kniebeschwerden beeinflussen könnten.
*   **Status nach aufrichtender Überbrückungsspondylodese Th11-L1:** Dies bezieht sich auf eine frühere Operation des Rückens (Wirbelsäulenversteifung).
*   **Mögliche Anschlussdegeneration der Wirbelsäule:** Dies ist eine Vermutung bzgl. möglicher Problemen im Bereich der Wirbelsäule.
*   **Chondropathie Grad 4 (medialer Femurkondylus):** Eine Knorpelschädigung im Knie.
*   **Teilresezierten Innenmeniskus:** Beschädigung des Innenmeniskus.
*   **Auffaserung Aussenmeniskus:**  Veränderung des Außenmeniskus.
*   **Hyperkyphose des thoracolumbalen Übergangs:** Eine Verkrümmung der Wirbelsäule.


----------------

Er ist sogar so freundlich, alles in laiengerechte Sprache zu übersetzen. 

Weiteres Beispiel der semantischen Analyse:

<span style="color:green">&gt;Bitte finde die Austrittsmedikation in folgendem Text: (PDF-Inhalt)</span>

> Hier ist die Liste der Medikamente, die dem Patienten bei Austritt verschrieben wurden, basierend auf dem Text:
*   **Xarelto (Filmtabl. 20 mg)** - Rivaroxaban Filmtabl. 20mg (1 Stk p.o.)
*   **Bilol (Filmtabl. 5 mg)** - Bisoprolol Filmtabl. 5mg (1 Stk p.o.)
*   **Amiodarone Zentiva (Tabl. 200 mg)** -  Für 2 Wochen 200mg 1-0-1, danach 200mg 1x täglich für 3 Monate.
*   **Exforge HCT (Filmtabl.)** - Amlodipin, Valsartan, Hydrochlorothiazid Filmtabl. 10mg, 160mg, 25mg (1 Stk p.o.)
*   **Pantozol (Filmtabl. 40 mg)** - Pantoprazol Filmtabl. 40mg (1 Stk p.o.)
*   **Xanax (Tabl. 0.5 mg)** - Alprazolam Tabl. 0.5mg (bei Bedarf 1 Stk p.o.)

Wohlbemerkt: Das ist ein vier Seiten umfassendes PDF. Mit relativ wenig Zusatzaufwand könnte man das direkt in die KG übernehmen.

### Datenschutzbedenken

Selbstverständlich dürften Sie einen solchen Auftrag niemals einer frei zugänglichen KI (ChatGPT, Gemini, Claude, DeepSeek usw) übergeben, da Sie dafür ja das PDF mit sensiblen Patienendaten hochladen würden.
Aber bei einer KI, die nur lokal in Ihrem System läuft, ist das kein Problem (Testen Sie es: ziehen Sie den Netzwerk-Stecker. Es wird immer noch gleich funktionieren).

Die Kehrseite ist: Während die "grossen" KIs alles, was sie erhalten, auch benutzen, um sich weiterzuentwickeln (zum Besseren oder zum Schlechteren), bleibt unsere lokale KI statisch auf dem Stand, in dem wir sie heruntergeladen haben.
Sie kann also nicht "degradieren", aber sich auch nicht anpassen oder verbessern. Sie können sie aber jederzeit durch ein neueres oder ganz anderes Modell austauschen. Sie hat übrigens auch kein Gedächtnis: Wenn Sie in zehn Minuten fragen "Was war schon wieder die Hauptdiagnose?", dann werden Sie irgendeine wirre Antwort bekommen, die nichts mit dem eben analysierten Text zu tun hat.

Wie ich aber hier hoffentlich gezeigt habe, kann man auf dem heutigen Stand schon recht viel machen.

### Wie bekommt man es zum Laufen?

Ein kurzes Wort zur benötigen Hardware:

LLMs laufen bevorzugt auf Grafikkarten, da diese viele Operationen parallel ausführen können (Genau wie sie beim Bildaufbau alle Pixel möglichst gleichzeitig neu berechnen müssen). LLMs arbeiten auch mit vielen gleichzeitig ablaufenden Operationen. Am besten funktionieren sie darum, wenn möglichst viele "Neurone" in den Speicher der Grafikkarte passen.

Es ist empfehlenswert, eine Grafikkarte mit mindestens 16GB RAM zu kaufen. Wenn Geld keine Rolle spielt, kann man auch mehrere Grafikkarten einbauen. Am wenigsten Probleme hat man immer noch mit Grafikkarten mit NVidia-Chipsatz, da die meisten LLM Transformer damit zurechtkommen. Es muss keine High-End Karte sein, aber Mittelklasse wäre schon empfehlenswert. Bei mir laufen die hier vorgestellten Modelle auf einer NVidia 5060 Ti (nicht verwechseln mit 5060 ohne Ti) einigermassen gut. Die kosten derzeit (Mitte 2025) zwischen CHF 400.- und 500.- (Achten Sie wie gesagt darauf, dass Sie mindestens 16GB Speicher bekommen). Natürlich wären stärkere Karten mit mehr Speicher noch besser, aber ein Modell mit doppelt so viel Speicher kostet locker den sechsfachen Preis...

Auch am Arbeitsspeicher des Rechners sollte man nicht knausern. Mindestens 48GB sind empfehlenswert, 64GB besser. Der Prozessor ist dagegen nicht so wichtig, wobei es auch hier eher auf die Zahl der Kerne als auf deren Einzelgeschwindigkeit ankommt.

Damit die Grafikkarte für KI verwendet werden kann, ist ausserdem das [CUDA-Toolkit](https://developer.nvidia.com/cuda-toolkit) erforderlich, das man relativ einfach direkt von NVidia herunterladen und installieren kann.

### Was nimmt man überhaupt?

Wenn Sie sich mit KI beschäftigen, begegnen Sie häufig diesen südamerikanischen Nutztieren: LLama, Ollama, Alpaca und so weiter. Der Name leitet sich ursprünglich von LLM (also large language Model) ab, wurde aber von Meta rückakronymisiert (Large Language Model Meta AI). Meta (also der Facebook-Konzern, ja, ausgerechnet!) hat die KI gewissermasen demokratisiert, indem es ihr LLM als OpenSouce publiziert hat. Seither ist ein riesiges Ökosystem entstanden.
Wenn Sie sich einen Überblick verschaffen wollen, besuchen Sie die [Hugging Face](https://huggingface.co/) Website und lassen Sie sich von den Unmengen an Information und Modellen dort erschlagen.

Wenn Sie es sich etwas einfacher machen wollen, laden Sie z.B. [Ollama](https://ollama.com/) herunter. Ollama baut eine Oberfläche und ein API um LLM-Modelle und erlaubt Ihnen auch die Auswahl solcher [Modelle](https://ollama.com/library). Nach der Installation können Sie einfach mit `ollama run modellname` das gewünschte Modell herunterladen und starten. Wenn Ihnen der dann präsentierte Text-Prompt nicht gefällt, gibt es auch eine Reihe von [GUIs](https://github.com/ollama/ollama?tab=readme-ov-file#community-integrations),probieren Sie z.B. [Hollama](https://github.com/fmaclen/hollama).

Wählen Sie zuerst mal ein kleines Modell (Eines mit :3b oder :4b im Namen), und wenn alles läuft können Sie grössere Modelle ausprobieren, bis Sie an die Grenzen Ihres PC stossen.
